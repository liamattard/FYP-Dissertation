\subsection{Automatic User Profiling} 

The following evaluates the performance results of the
three CNNs used to classify the users' social media images.

\paragraph{Training results from the TensorFlow Keras sequential model}

We trained this model using the NVIDIA Tesla K80 GPU provided by Google Colab. At 16 epochs,
the model starts to overfit as the validation loss starts to increase, as shown
in figure~\ref{kerasresults}. This is why we chose to calculate the model's performance on the
testing set in the following subsections using the first 16 epochs. 

\begin{figure}[h]
\centering
\includegraphics[width=0.6\textwidth]{Epoch_20.png}
\caption{Training and validation accuracy of the model on the testing and validation dataset}
\label{kerasresults}
\end{figure}

\paragraph{Performance comparison of the three models}

The testing dataset consists of 500 images gathered using the Unsplash API. We
calculated the Accuracy, Precision, Recall and F1 Score on the testing set to
evaluate the models by calculating the number of true positive (TP), true
negative  (TN), false-negative (FN) and false positive (FP) as a
percentage over the dataset. 

The accuracy of the models, shown in figure~\ref{accuracy}, is represented by:

\[Accuracy = \frac{TP+TN}{TP+FP+FN+TN} \]

This shows how many category predictions a model got right. In this case, the Resnet 50,
Resnet 18, and Keras models have an average 93.7\%, 92.4\%, and 88.7\% average accuracy,
respectively. Overall, the models have high accuracy. Therefore, we need to rely on other
evaluation techniques.

\begin{figure}[h]
\centering
\includegraphics[width=0.7\textwidth]{Accuracy.png}
\caption{Accuracy of the models}
\label{accuracy}
\end{figure}

The precision of the models, shown in figure~\ref{precision}, represented by

\[Precision = \frac{TP}{TP+FP} \]
This represents the ratio of correct predictions over the total positive labels.
In this case, the Resnet 50, Resnet 18, and Keras models have an average 72.4\%, 66.7\%,
and 62.4\% precision rate, respectively. The Resnet 50 has the best average
overall; however, the Keras model performed better for the 'clubbing' and
'bars' categories but very poorly in the shopping category.

\begin{figure}[h]
\centering
\includegraphics[width=0.7\textwidth]{Precision.png}
\caption{Precision of the models}
\label{precision}
\end{figure}

The proportion of actual positive labels that the models identify correctly is
represented by the recall value calculated using 

\[Recall= \frac{TP}{TP+FN} \]

In this case, figure \ref{recall}
shows how for the clubbing and bar categories, although the Resnet models were
less accurate and less precise, they rarely labelled an image as a bar or a
club when they are not supposed to.

\begin{figure}[h]
\centering
\includegraphics[width=0.7\textwidth]{Recall.png}
\caption{Recall of the Resnet-18, Resnet-50 and Tensorflow Keras Sequential}
\label{recall}
\end{figure}

The F1 score is the weighted average of Precision and Recall measured using:

\[F1 Score = \frac{2*Recall*Precision}{Recall+Precision}  \]
The Reset 50 has a pretty consistent and high score on
the testing dataset with an average F1 score of 76.29., so
we decided to use it as our baseline for the tourist
itinerary generation application.

\begin{figure}[h]
\centering
\includegraphics[width=0.7\textwidth]{F1Score.png}
\caption{F1 score of the Resnet-18, Resnet-50 and Tensorflow Keras Sequential}
\label{f1}
\end{figure}

These results have shown how a CNN could classify photos into the six
application characteristics. Although all of the models achieved valid results,
the Resnet 50 model was the best performer. Therefore, we will be using this
model for our application.
